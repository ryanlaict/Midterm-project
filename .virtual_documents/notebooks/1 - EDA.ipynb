





# (this is not an exhaustive list of libraries)
import pandas as pd
import numpy as np
import os
import json
import re
from pprint import pprint
from functions_variables import encode_tags
from functions_variables import encode_primary_photo
from functions_variables import encode_source
from functions_variables import extract_city_state





# Directory containing JSON files on personal computer
## Might need to change before final commit
directory = r"C:\Users\lai29\OneDrive - UBC\Documents\GitHub\Midterm-project\data"

# Initialize an empty list to store data
data_list = []

# # Function to flatten nested JSON columns 

'''
Creation of a function that would flatten several columns - is this necessary? 
The columns information looks to be info that would be unnecessary and can be dropped from the data.
'''
# def flatten_json(record):
#     flat_record = record.copy()

#     # Flatten description
#     if "description" in record and isinstance(record["description"], dict):
#         flat_record.update(record["description"])
#         del flat_record["description"]

#     # Flatten location
#     if "location" in record and isinstance(record["location"], dict):
#         if "address" in record and isinstance(record["location"]["address"], dict):
#             flat_record.update(record["location"]["address"])
#         if "coordinate" in record and isinstance(record["location"]["coordinate"], dict):
#             flat_record["latitude"] = record["location"]["coordinate"].get("lat")
#             flat_record["longitude"] = record["location"]["coordinate"].get("lon")
#         del flat_record["location"]

#     # Flatten products (dictionary)
#     if "products" in record and isinstance(record["products"], dict):
#         flat_record.update(pd.json_normalize(record["products"]).to_dict(orient="records")[0])
#         del flat_record["products"]

#     return flat_record

# Loop through each JSON file in the directory
for filename in os.listdir(directory):
    if filename.endswith(".json"):
        file_path = os.path.join(directory, filename)
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                data = json.load(file)  # Load JSON data

            # Check if expected keys exist before accessing them
            if isinstance(data, dict) and "data" in data and isinstance(data["data"], dict) and "results" in data["data"]:
                for record in data["data"]["results"]:
                    if isinstance(record, dict):  # Ensure record is a dictionary before processing
                        flat_record = flatten_json(record)
                        data_list.append(flat_record)

        except json.JSONDecodeError as e:
            print(f"Error decoding JSON in file {filename}: {e}")
# Convert list of dictionaries into a DataFrame
df_combined = pd.DataFrame(data_list)

# Display or save the combined DataFrame
print(df_combined.head())  # View first few rows
df_combined.to_csv("combined_data.csv", index=False)


df_combined = pd.read_csv("combined_data.csv")


# Check df_combined
df_combined.head()


df_combined.describe()


df_combined.info()


df_combined.dtypes

#Create a list of categorical variables
categorical = df_combined.select_dtypes(include=['object']).columns

#Create a list of numerical variables
numerical = df_combined.select_dtypes(exclude=['object']).columns

print(categorical)
print(numerical)


df_combined['community'].value_counts()


df_combined['permalink'].head()


# Columns to drop
columns_to_drop = ['last_update_date','branding','flags','open_houses','status','lead_attributes' ,'property_id', 'photos', 'listing_id','other_listings', 'community', 'products',
       'virtual_tours',]

# Drop the unneeded columns
df_dropped = df_combined.drop(columns=columns_to_drop)


df_dropped.head()


# Encode Tags on df_dropped
df_encoded = encode_tags(df_dropped)

df_encoded.head()


# Encode Primary Photo on df_encoded
df_encoded = encode_primary_photo(df_encoded)

df_encoded.head()


# Run encode_source function
df_encoded = encode_source(df_encoded)

df_encoded.head()


# Convert to datetime format
df_encoded['list_date'] = pd.to_datetime(df_encoded['list_date'], errors='coerce')

# Format as MM-DD-YYYY
df_encoded['list_date'] = df_encoded['list_date'].dt.strftime('%m-%d-%Y')

df_encoded.head()


df_encoded['permalink'].head()


# Run extract_city_state function
df_encoded = extract_city_state(df_encoded)

df_encoded[['city','state']].head(-40)


# Save a copy of df_encoded csv
df_encoded.to_csv("encoded_data.csv", index=False)








# load and concatenate data here
# drop or replace values as necessary








# OHE categorical variables/ tags here
# tags will have to be done manually








# perform train test split here
# do something with state and city





# import, join and preprocess new data here





# perform EDA here









