


# import models and fit
import numpy as np
import pandas as pd
import xgboost as xgb
from functions_variables import evaluate_model
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.feature_selection import RFE


#Setting up data for Train/Test Split
# Load data from chosen_features.csv
data = pd.read_csv('processed/chosen_features.csv') #Using Cleaned Up Dataset: Chosen Features

# Define X,y
X = data.drop(columns = ['sold_price'], axis=1) #Dropping Target
y = data['sold_price'] #Target

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 


#Confirming shapes
print(data.shape)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)


# Run Regression models on entire feature set from chosen_features
# Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Lasso Regression
lasso_model = Lasso(alpha=1000)
lasso_model.fit(X_train, y_train)

# Ridge Regression
ridge_model = Ridge(alpha=100)
ridge_model.fit(X_train, y_train)

# Support Vector Regression (SVR)
svr_model_rbf = SVR(kernel='rbf')
svr_model_rbf.fit(X_train, y_train)

# Support Vector Regression (SVR)
svr_model_linear = SVR(kernel='linear')
svr_model_linear.fit(X_train, y_train)

# Random Forest Regression
rf_model = RandomForestRegressor(n_estimators=100)
rf_model.fit(X_train, y_train)

# XGBoost Regression
xgb_model = xgb.XGBRegressor(objective='reg:absoluteerror')
xgb_model.fit(X_train, y_train)

#XGBoost Huber Regression
xgb_model_log = xgb.XGBRegressor(objective='reg:pseudohubererror')
xgb_model_log.fit(X_train, y_train)


# Define function to evaluate models
def evaluate_model(model, X_test, y_test):
    """Prints MAE, RMSE, and R² for a given model"""
    y_pred = model.predict(X_test)
    
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    print(f"{model.__class__.__name__}:")
    print(f"  MAE:  {mae:.4f}")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  R²:   {r2:.4f}\n")

# List models being evaluated
models = [lr_model, lasso_model, ridge_model, svr_model_rbf, svr_model_linear, rf_model, xgb_model, xgb_model_log]

for model in models:
    evaluate_model(model, X_test, y_test)


# Check feature magnitudes
print(X_train.describe())  


# Rescale data to see if SVR Linear performs better/differently
from sklearn.preprocessing import StandardScaler

# Define scaler, X_train_scaled, X_test_scaled
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Run SVR Linear again to see if we get better evaluation metrics
svr_model_linear.fit(X_train, y_train)

# Evaluate VR Linear model after rescaling
evaluate_model(svr_model_linear, X_test, y_test)


# Polynomial Regression (using PolynomialFeatures)
poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False) #Unable to run higher than 4 due to number of columns slowing down system
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)
poly_model = LinearRegression()
poly_model.fit(X_train_poly, y_train)

# Predictions
y_train_pred = poly_model.predict(X_train_poly)
y_test_pred = poly_model.predict(X_test_poly)

# Evaluate model performance
def evaluate_poly_model(y_true, y_pred, dataset_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mse)

    print(f"\nPolynomial Regression Model - {dataset_name} Metrics:")
    print(f"MAE: {mae:.4f}")
    print(f"MSE: {mse:.4f}")
    print(f"R²: {r2:.4f}")
    print(f"RMSE: {rmse:.4f}")

# Print feature expansion
print(f"Original features: {X_train.shape[1]}")
print(f"Expanded polynomial features: {X_train_poly.shape[1]}")

# Print train & test metrics
evaluate_poly_model(y_train, y_train_pred, "Training")
evaluate_poly_model(y_test, y_test_pred, "Testing")


# Polynomial Regression (using Ridge and PolynomialFeatures)
ridge_poly_model = Ridge(alpha=1.0)
ridge_poly_model.fit(X_train_poly, y_train)
y_train_pred_ridge = ridge_poly_model.predict(X_train_poly)
y_test_pred_ridge = ridge_poly_model.predict(X_test_poly)

# Evaluate model performance
def evaluate_poly_model(y_true, y_pred, dataset_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mse)

    print(f"\nPolynomial Regression Model - {dataset_name} Metrics:")
    print(f"MAE: {mae:.4f}")
    print(f"MSE: {mse:.4f}")
    print(f"R²: {r2:.4f}")
    print(f"RMSE: {rmse:.4f}")

# Print feature expansion
print(f"Original features: {X_train.shape[1]}")
print(f"Expanded polynomial features: {X_train_poly.shape[1]}")

# Print train & test metrics
evaluate_poly_model(y_train, y_train_pred_ridge, "Training")
evaluate_poly_model(y_test, y_test_pred_ridge, "Testing")


# Polynomial Regression (using Ridge and PolynomialFeatures)
ridge_poly_model = Ridge(alpha=10.0)  # Try higher alpha to see if that corrects the correlation error
ridge_poly_model.fit(X_train_poly, y_train)
y_train_pred_ridge = ridge_poly_model.predict(X_train_poly)
y_test_pred_ridge = ridge_poly_model.predict(X_test_poly)

# Evaluate model performance
def evaluate_poly_model(y_true, y_pred, dataset_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mse)

    print(f"\nPolynomial Regression Model - {dataset_name} Metrics:")
    print(f"MAE: {mae:.4f}")
    print(f"MSE: {mse:.4f}")
    print(f"R²: {r2:.4f}")
    print(f"RMSE: {rmse:.4f}")

# Print feature expansion
print(f"Original features: {X_train.shape[1]}")
print(f"Expanded polynomial features: {X_train_poly.shape[1]}")

# Print train & test metrics
evaluate_poly_model(y_train, y_train_pred_ridge, "Training")
evaluate_poly_model(y_test, y_test_pred_ridge, "Testing")


from sklearn.model_selection import RandomizedSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import make_scorer, mean_squared_error

# Hyperparameter grid 
param_dist = {
    'n_estimators': [50, 100, 200, 500],
    'max_features': [None, 'sqrt', 'log2'],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Define rf_tuned_model
rf_tuned_model = RandomForestRegressor(random_state=42)

# Define random_search params
random_search = RandomizedSearchCV(
    rf_tuned_model, 
    param_distributions=param_dist, 
    n_iter=20, 
    cv=5, 
    scoring='neg_root_mean_squared_error', 
    random_state=42, 
    error_score=np.nan
)

# Fit random_search
random_search.fit(X_train, y_train)

# Best parameters and score
print("Best Random Forest Model:", random_search.best_params_)
print("Best CV score (RMSE):", -random_search.best_score_)

# Perform cross-validation on best model
best_rf = random_search.best_estimator_
cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')

print(f"Cross-validation RMSE: {cv_scores.mean():.4f}")

# Print feature importances
feature_importance = pd.DataFrame(
    {'Feature': X_train.columns, 'Importance': best_rf.feature_importances_}
).sort_values(by='Importance', ascending=False)

print("\nFeature Importances from Best Random Forest Model:")
print(feature_importance.head(10))  # Show features in order of importance


# Same as above but with n_iter = 50 instead
# Hyperparameter grid 
param_dist = {
    'n_estimators': [50, 100, 200, 500],
    'max_features': [None, 'sqrt', 'log2'],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Define rf_tuned_model
rf_tuned_model = RandomForestRegressor(random_state=42)

# Define random_search params
random_search = RandomizedSearchCV(
    rf_tuned_model, 
    param_distributions=param_dist, 
    n_iter=50, 
    cv=5, 
    scoring='neg_root_mean_squared_error', 
    random_state=42, 
    error_score=np.nan
)

# Fit random_search
random_search.fit(X_train, y_train)

# Best parameters and score
print("Best Random Forest Model:", random_search.best_params_)
print("Best CV score (RMSE):", -random_search.best_score_)

# Perform cross-validation on best model
best_rf = random_search.best_estimator_
cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')
print(f"Cross-validation RMSE: {cv_scores.mean():.4f}")

# Print feature importances
feature_importance = pd.DataFrame(
    {'Feature': X_train.columns, 'Importance': best_rf.feature_importances_}
).sort_values(by='Importance', ascending=False)

print("\nFeature Importances from Best Random Forest Model:")
print(feature_importance.head(10))  # Show features in order of importance


from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Lasso, Ridge

# Define parameter grid
param_grid = {'alpha': [0.1, 1, 10, 100, 1000]}  # values to test for Alpha

# Define Lasso Regression
lasso = Lasso(max_iter=10000)

# Define LAsso Regression params
lasso_grid_search = GridSearchCV(
    lasso, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=1
)


# Fit Lasso regression
lasso_grid_search.fit(X_train, y_train)
print(f"Best alpha for Lasso: {lasso_grid_search.best_params_}, Best RMSE: {-lasso_grid_search.best_score_:.4f}")

# Define Ridge Regression
ridge = Ridge(max_iter=10000)

# Define Ridge Regression params
ridge_grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=1)

# Fit Ridge Regression
ridge_grid_search.fit(X_train, y_train)
print(f"Best alpha for Ridge: {ridge_grid_search.best_params_}, Best RMSE: {-ridge_grid_search.best_score_:.4f}")


from sklearn.tree import DecisionTreeRegressor

# Initialize model
dt_model = DecisionTreeRegressor(random_state=10)
dt_model.fit(X_train, y_train)

# Make predictions and calculate metrics
y_pred = dt_model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mse)

# Print results
print("Decision Tree Regression:")
print(f"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSE: {rmse}")


from sklearn.neighbors import KNeighborsRegressor

# Initialize model
knn_model = KNeighborsRegressor()
knn_model.fit(X_train, y_train)

# Calculate initial Score
y_pred = knn_model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mse)

# Print results
print("K-Nearest Neighbors Regression:")
print(f"MAE: {mae}, MSE: {mse}, R2: {r2}, RMSE: {rmse}")





# gather evaluation metrics and compare results
# Combine model information
models = [lr_model, lasso_model, ridge_model, svr_model_rbf, svr_model_linear, rf_model, xgb_model, knn_model, dt_model]
model_names = ['Linear Regression', 'Lasso Regression', 'Ridge Regression','Support Vector Regression (RBF)','Support Vector Regression (Linear)', 'Random Forest Regression', 'XGBoost Regression', 'Nearest Neighbour', 'Decision Tree']
model_scores = []

# model scores
for model, name in zip(models, model_names):
    y_pred = model.predict(X_test)            
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mse)  # Calculate RMSE
    model_scores.append((name, mae, mse, r2, rmse))

# Print results for each model
for name, mae, mse, r2, rmse in model_scores:
    print(f"Model: {name}")
    print(f"Mean Absolute Error: {mae}")
    print(f"Mean Squared Error: {mse}")
    print(f"R-squared: {r2}")
    print(f"RMSE: {rmse}")
    print() #Empty line between


# Convert model scores into a DataFrame
columns = ["Model", "MAE", "MSE", "R²", "RMSE"]
df_scores = pd.DataFrame(model_scores, columns=columns)

# View model effectiveness by R2
df_scores.sort_values('R²', ascending= False)








# perform feature selection 
# refit models
# gather evaluation metrics and compare to the previous step (full feature set)


# Moving forward to test Linear Regression and Random Forest further
# Determine features to drop, if any from RandomForest

# Get feature importances from Random Forest
rf_importance = rf_model.feature_importances_

# Convert to DataFrame
rf_feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': rf_importance
}).sort_values(by='Importance', ascending=True)  # Sort least important first

# Print least important features
print("Least Important Features (Random Forest):")
print(rf_feature_importance.head(5))  # Change to see more/less


# Determine features to drop, if any from LinearRegression

# Get absolute values of coefficients
lr_coefficients = np.abs(lr_model.coef_)

# Convert to DataFrame
lr_feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Coefficient': lr_coefficients
}).sort_values(by='Coefficient', ascending=True)  # Sort least important first

# Print least important features
print("Least Important Features (Linear Regression):")
print(lr_feature_importance.head(5))


# drop 2 features
drop_features_v1 = ['price_reduced_amount', 'garage']

# Update train, test
X_train_reduced_v1 = X_train.drop(columns=drop_features_v1)
X_test_reduced_v1 = X_test.drop(columns=drop_features_v1)


# Train new models for reduced_v1
lr_model_reduced_v1 = LinearRegression()
rf_model_reduced_v1 = RandomForestRegressor()

lr_model_reduced_v1.fit(X_train_reduced_v1, y_train)
rf_model_reduced_v1.fit(X_train_reduced_v1, y_train)

# Generate predictions for the reduced_v1 feature set
y_pred_lr_reduced_v1 = lr_model_reduced_v1.predict(X_test_reduced_v1)
y_pred_rf_reduced_v1 = rf_model_reduced_v1.predict(X_test_reduced_v1)

# Compute metrics for reduced_v1 models
r2_lr_reduced_v1 = r2_score(y_test, y_pred_lr_reduced_v1)
rmse_lr_reduced_v1 = np.sqrt(mean_squared_error(y_test, y_pred_lr_reduced_v1))

r2_rf_reduced_v1 = r2_score(y_test, y_pred_rf_reduced_v1)
rmse_rf_reduced_v1 = np.sqrt(mean_squared_error(y_test, y_pred_rf_reduced_v1))

# Extract previous R² and RMSE for Linear Regression and Random Forest
r2_lr_original = next(r2 for name, _, _, r2, _ in model_scores if name == "Linear Regression")
r2_rf_original = next(r2 for name, _, _, r2, _ in model_scores if name == "Random Forest Regression")

rmse_lr_original = next(rmse for name, _, _, _, rmse in model_scores if name == "Linear Regression")
rmse_rf_original = next(rmse for name, _, _, _, rmse in model_scores if name == "Random Forest Regression")

# Print side-by-side comparison
print("\nModel Performance Comparison\n")

print("Linear Regression:")
print(f"R²: {r2_lr_original:.4f}  |  R² Reduced_v1: {r2_lr_reduced_v1:.4f}")
print(f"RMSE: {rmse_lr_original:.4f}  |  RMSE Reduced_v1: {rmse_lr_reduced_v1:.4f}\n")

print("Random Forest:")
print(f"R²: {r2_rf_original:.4f}  |  R² Reduced_v1: {r2_rf_reduced_v1:.4f}")
print(f"RMSE: {rmse_rf_original:.4f}  |  RMSE Reduced_v1: {rmse_rf_reduced_v1:.4f}")


# drop 1 feature
drop_features_v2 = ['price_reduced_amount']

# Update train, test
X_train_reduced_v2 = X_train.drop(columns=drop_features_v2)
X_test_reduced_v2 = X_test.drop(columns=drop_features_v2)


# Train new models for reduced_v2
lr_model_reduced_v2 = LinearRegression()
rf_model_reduced_v2 = RandomForestRegressor()

lr_model_reduced_v2.fit(X_train_reduced_v2, y_train)
rf_model_reduced_v2.fit(X_train_reduced_v2, y_train)

# Generate predictions for the reduced_v2 feature set
y_pred_lr_reduced_v2 = lr_model_reduced_v2.predict(X_test_reduced_v2)
y_pred_rf_reduced_v2 = rf_model_reduced_v2.predict(X_test_reduced_v2)

# Compute metrics for reduced_v2 models
r2_lr_reduced_v2 = r2_score(y_test, y_pred_lr_reduced_v2)
rmse_lr_reduced_v2 = np.sqrt(mean_squared_error(y_test, y_pred_lr_reduced_v2))

r2_rf_reduced_v2 = r2_score(y_test, y_pred_rf_reduced_v2)
rmse_rf_reduced_v2 = np.sqrt(mean_squared_error(y_test, y_pred_rf_reduced_v2))

# Extract previous R² and RMSE for Linear Regression and Random Forest
r2_lr_original = next(r2 for name, _, _, r2, _ in model_scores if name == "Linear Regression")
r2_rf_original = next(r2 for name, _, _, r2, _ in model_scores if name == "Random Forest Regression")

rmse_lr_original = next(rmse for name, _, _, _, rmse in model_scores if name == "Linear Regression")
rmse_rf_original = next(rmse for name, _, _, _, rmse in model_scores if name == "Random Forest Regression")

# Print side-by-side comparison
print("\nModel Performance Comparison\n")

print("Linear Regression:")
print(f"R²: {r2_lr_original:.4f}  |  R² Reduced_v1: {r2_lr_reduced_v1:.4f}  |  R² Reduced_v2: {r2_lr_reduced_v2:.4f}")
print(f"RMSE: {rmse_lr_original:.4f}  |  RMSE Reduced_v1: {rmse_lr_reduced_v1:.4f}  |  RMSE Reduced_v2: {rmse_lr_reduced_v2:.4f}\n")

print("Random Forest:")
print(f"R²: {r2_rf_original:.4f}  |  R² Reduced_v1: {r2_rf_reduced_v1:.4f}  |  R² Reduced_v2: {r2_rf_reduced_v2:.4f}")
print(f"RMSE: {rmse_rf_original:.4f}  |  RMSE Reduced_v1: {rmse_rf_reduced_v1:.4f}  |  RMSE Reduced_v2: {rmse_rf_reduced_v2:.4f}")


# Make a copy of the original feature set to avoid overwriting
X_train_copy_rfe = X_train.copy()
X_test_copy_rfe = X_test.copy()

# Apply RFE to select top 5 features using Random Forest
rfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=5)
X_train_rfe = rfe.fit_transform(X_train_copy_rfe, y_train)
X_test_rfe = rfe.transform(X_test_copy_rfe)

# Get selected feature names
selected_features = X_train.columns[rfe.support_]
print("Selected Features After RFE:", list(selected_features))
print(f"Number of Features Selected: {X_train_rfe.shape[1]}")

# Train new models on RFE-selected features
lr_model_rfe = LinearRegression()
rf_model_rfe = RandomForestRegressor()

lr_model_rfe.fit(X_train_rfe, y_train)
rf_model_rfe.fit(X_train_rfe, y_train)

# Generate predictions for RFE-selected features
y_pred_lr_rfe = lr_model_rfe.predict(X_test_rfe)
y_pred_rf_rfe = rf_model_rfe.predict(X_test_rfe)

# Compute performance metrics
r2_lr_rfe = r2_score(y_test, y_pred_lr_rfe)
rmse_lr_rfe = np.sqrt(mean_squared_error(y_test, y_pred_lr_rfe))

r2_rf_rfe = r2_score(y_test, y_pred_rf_rfe)
rmse_rf_rfe = np.sqrt(mean_squared_error(y_test, y_pred_rf_rfe))

# Print model performance after RFE
print("\nModel Performance with RFE-Selected Features\n")

print("Linear Regression:")
print(f"R²: {r2_lr_rfe:.4f}")
print(f"RMSE: {rmse_lr_rfe:.4f}\n")

print("Random Forest:")
print(f"R²: {r2_rf_rfe:.4f}")
print(f"RMSE: {rmse_rf_rfe:.4f}")


# Make a copy of the original feature set to avoid overwriting
X_train_copy_rfe_lr = X_train.copy()
X_test_copy_rfe_lr = X_test.copy()

# Apply RFE to select top 5 features using Linear Regression
rfe = RFE(estimator=LinearRegression(), n_features_to_select=5)
X_train_rfe_lr = rfe.fit_transform(X_train_copy_rfe_lr, y_train)
X_test_rfe_lr = rfe.transform(X_test_copy_rfe_lr)

# Get selected feature names
selected_features = X_train.columns[rfe.support_]
print("Selected Features After RFE:", list(selected_features))
print(f"Number of Features Selected: {X_train_rfe_lr.shape[1]}")

# Train new models on RFE-selected features
lr_model_rfe_lr = LinearRegression()
rf_model_rfe_lr = RandomForestRegressor()

lr_model_rfe_lr.fit(X_train_rfe_lr, y_train)
rf_model_rfe_lr.fit(X_train_rfe_lr, y_train)

# Generate predictions for RFE-selected features
y_pred_lr_rfe_lr = lr_model_rfe_lr.predict(X_test_rfe_lr)
y_pred_rf_rfe_lr = rf_model_rfe_lr.predict(X_test_rfe_lr)

# Compute performance metrics
r2_lr_rfe_lr = r2_score(y_test, y_pred_lr_rfe_lr)
rmse_lr_rfe_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr_rfe_lr))

r2_rf_rfe_lr = r2_score(y_test, y_pred_rf_rfe_lr)
rmse_rf_rfe_lr = np.sqrt(mean_squared_error(y_test, y_pred_rf_rfe_lr))

# Print model performance after RFE
print("\nModel Performance with RFE_LR-Selected Features\n")

print("Linear Regression:")
print(f"R²: {r2_lr_rfe_lr:.4f}")
print(f"RMSE: {rmse_lr_rfe_lr:.4f}\n")

print("Random Forest:")
print(f"R²: {r2_rf_rfe_lr:.4f}")
print(f"RMSE: {rmse_rf_rfe_lr:.4f}")





#Test for PCA values
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest

test_dataset = pd.read_csv('cleaned_income_merged_data.csv')

# Separate features and target
X = test_dataset.drop(columns=['sold_price'])
y = test_dataset['sold_price']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply PCA
pca = PCA(n_components=0.95)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Apply SelectKBest
kbest = SelectKBest(k=5)
X_train_kbest = kbest.fit_transform(X_train, y_train)
X_test_kbest = kbest.transform(X_test)

# Train models
lr_model_pca = LinearRegression()
rf_model_pca = RandomForestRegressor()

lr_model_pca.fit(X_train_pca, y_train)
rf_model_pca.fit(X_train_pca, y_train)

# Generate predictions
y_pred_lr_pca = lr_model_pca.predict(X_test_pca)
y_pred_rf_pca = rf_model_pca.predict(X_test_pca)

# Compute metrics
r2_lr_pca = r2_score(y_test, y_pred_lr_pca)
rmse_lr_pca = np.sqrt(mean_squared_error(y_test, y_pred_lr_pca))

r2_rf_pca = r2_score(y_test, y_pred_rf_pca)
rmse_rf_pca = np.sqrt(mean_squared_error(y_test, y_pred_rf_pca))

# Print model performance
print("\nModel Performance with PCA-Selected Features\n")

print("Linear Regression:")
print(f"R²: {r2_lr_pca:.4f}")

print("Random Forest Regression:")
print(f"R²: {r2_rf_pca:.4f}")


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.pipeline import Pipeline
import numpy as np

# Load dataset
test_dataset = pd.read_csv('cleaned_income_merged_data.csv')

# Separate features and target
X = test_dataset.drop(columns=['sold_price'])
y = test_dataset['sold_price']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create the pipeline with SelectKBest and PCA
# SelectKBest will first select the top 5 features based on univariate statistics (f_regression for regression)
# PCA will then reduce the dimensionality of the selected features
pipeline = Pipeline([
    ('kbest', SelectKBest(score_func=f_regression, k=5)),
    ('pca', PCA(n_components=0.99)),  # Keep 95% variance
])

# Apply the pipeline to the training data
X_train_selected = pipeline.fit_transform(X_train, y_train)
X_test_selected = pipeline.transform(X_test)

# Train models on the transformed data
lr_model = LinearRegression()
rf_model = RandomForestRegressor()

lr_model.fit(X_train_selected, y_train)
rf_model.fit(X_train_selected, y_train)

# Generate predictions
y_pred_lr = lr_model.predict(X_test_selected)
y_pred_rf = rf_model.predict(X_test_selected)

# Compute metrics
r2_lr = r2_score(y_test, y_pred_lr)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))

r2_rf = r2_score(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))

# Print model performance
print("\nModel Performance with SelectKBest + PCA\n")

print("Linear Regression:")
print(f"R²: {r2_lr:.4f}")
print(f"RMSE: {rmse_lr:.4f}")

print("\nRandom Forest Regression:")
print(f"R²: {r2_rf:.4f}")
print(f"RMSE: {rmse_rf:.4f}")

